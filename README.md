# MT Exercise 4: Byte Pair Encoding, Beam Search
### *** Authors: Yuan Yu (19-763-291)â€ƒXiaoduan Liu (23-749-609) ****

**Note** 
Due to the large file size, we have also provided a Google Drive link to access all of our data and files.

**Links of Documents:**
1. Google Drive:
https://drive.google.com/drive/folders/1k4fODvmoxFy0WyyzLVLsyYt9iKX5_3UE?usp=sharing

2. Google Doc for our Report:
https://docs.google.com/document/d/1uHPphLe_4iqlqK5y2Ly5KOogXoxmJrQDaPN8bQ1Txew/edit?usp=sharing 

3. Github link:
https://github.com/yyyuanfish/mt-exercise-4/tree/main


This repository is a starting point for the 4th and final exercise. As before, fork this repo to your own account and then clone it into your preferred directory.



---

## 1â€‚Overview

| Part | Goal | Main Scripts |
|------|------|-------------|
| **A** | Clean & prepare ENâ†’IT data; learn/apply BPE (2 k / 8 k / 16 k). | `prepare_data.sh`, `check_data.sh` |
| **B** | Train three models: `word_2k`, `bpe_2k`, `bpe_8k`. | `train.sh`, `evaluate.sh` |
| **C** | Sweep 10 beam sizes (1 â†’ 512) on best model (`bpe_8k`). | `beam_experiment.sh`, `plot_results.py` |

> **Note**â€‚`bpe_2k` and `bpe_8k` were trained on **different laptops**, so their raw outputs may differ, but both runs used the same `train.sh` and `evaluate.sh` scripts.

---

## 2 Requirements

* Python â‰¥ 3.10  
* **virtualenv** â€“ `pip install virtualenv`  
* PyTorch + Joey-NMT (see Exercise 3 setup)  
* `sacremoses`, `sacrebleu >= 2.5.1`

- Python 3.10 must be installed. The command `python3` (or `python` on Windows) should be available from your terminal or command prompt.
- `virtualenv` must be installed. Install it with:

  ```bash
  pip install virtualenv

macOS/Linux users: No special setup needed; shell scripts should run normally.

Windows users: Either use Windows Subsystem for Linux (WSL) or a Unix-compatible shell like Git Bash.
If you're using PowerShell or Command Prompt, manual setup is required.


### 3 Setup Instructions

## For macOS / Linux / WSL / Git Bash users

*** Using bash ***
git clone <your-fork-url> mt-exercise-4
cd mt-exercise-4

python3 -m venv venv
source venv/bin/activate     # Windows WSL: source venv/bin/activate

pip install -r requirements.txt
pip install sacremoses sacrebleu



### 4â€‚Data-Preparation Scripts
1. prepare_data.sh:
1) 100 k random sub-sample â†’ 
2) tokenise â†’ 
3) clean &apos; â†’ ' â†’ 
4) learn joint BPE (2 k / 8 k / 16 k) â†’ 
5) build joint vocab â†’ 
6) apply BPE to train/dev/test.

2. check_data.sh:
Line counts, empty-line scan, sample preview, <unk> count, quick chrF smoke test.

#### Key Artefacts after running prepare_data.sh (BPE = 2000):
| File                            | Role                           | Generated by                |
| ------------------------------- | ------------------------------ | --------------------------- |
| `sampled_data/bpe2000.codes`    | BPE merge rules                | `learn-joint-bpe-and-vocab` |
| `vocab2000.en` / `vocab2000.it` | Lang-specific BPE vocabularies | same                        |
| `vocab2000.joint`               | Joint vocab (EN+IT)            | concat + `sort -u`          |
| `*.bpe2000.en` / `*.bpe2000.it` | BPE-segmented corpora          | `apply-bpe`                 |

### 5 Training Scripts & Key Fixes
* train.sh â€“ takes model name as argument; auto-detects CPU cores; writes logs to logs/<model>; sets overwrite: true.
* evaluate.sh â€“ detects correct test file, optional beam_size, strips @@, logs BLEU + chrF.
* Scheduler fix â€“ all YAMLs use scheduling: none to bypass the ReduceLROnPlateau verbose error.

### 6â€‚Common Errors & Solutions
| ID     | Error & Symptom                                     | Solution                                                      |
| ------ | --------------------------------------------------- | ------------------------------------------------------------- |
| **E1** | `ReduceLROnPlateau â€¦ verbose`                       | `scheduling: none`                                            |
| **E2** | `AssertionError: "model_file" not in tokenizer_cfg` | Proper nesting under `tokenizer:`                             |
| **E3** | `ConfigurationError: Unknown tokenizer type`        | Add `tokenizer_type: subword-nmt`, plus `codes`, `num_merges` |
| **E4** | `KeyError: 'bleu'` (BLEU missing)                   | Clean `&apos;`, upgrade sacrebleu, compute BLEU manually      |
| **E5** | Joey-NMT gives no BLEU when `eval_metric: bleu`     | Use `eval_metric: ppl`; BLEU via CLI                          |


### 7 Beam-Search Experiment
* Best model: bpe_8k
* Script: beam_experiment.sh (beam 1 â†’ 512)
* Results: beam_results/all_results.txt

#### plot_results.py outputs:

* BLEU vs Beam Size (log-x) â€“ peaks â‰ˆ beam 32â€“64, then plateaus.
* Time vs Beam Size (log-log) â€“ runtime grows ~ n^0.82.

#### Optimal trade-off: beam 32 or 64 (highest BLEU â‰ˆ 7.6, reasonable time).
Beams 256 / 512 crashed due to memory limits.


### 8â€‚Final Scores
| Model     | BLEU      | chrF2++ | Comment             |
| --------- | --------- | ------- | ------------------- |
| `word_2k` | **12.54** | 34.44   | baseline, 2 k words |
| `bpe_8k`  | **7.60**  | 31.2    | best subword model  |
| `bpe_2k`  | **1.79**  | 26.0    | over-segmented      |
Even after fixes, BLEU for bpe_2k stays low because of many <unk> tokens; chrF2++ shows the model still captures character patterns.

### 9â€‚Reproduce in One Go
# 1â€ƒPrepare data (creates sampled_data/)
bash scripts/prepare_data.sh

# 2â€ƒTrain (example: bpe_8k)
bash scripts/train.sh bpe_8k

# 3â€ƒEvaluate
bash scripts/evaluate.sh bpe_8k

# 4â€ƒBeam-size study
bash scripts/beam_experiment.sh
python plot_results.py

Happy translating!!! ðŸš€


### Other Instructions:
Clone your fork of the repository + Create a virtual environment:
   ```
   git clone https://github.com/[your-username]/mt-exercise-4
   cd mt-exercise-4 

   ```
    ./scripts/make_virtualenv.sh

Important: Then activate the env by executing the source command that is output by the shell script above.

Install required dependencies - Follow the instructions provided in the exercise PDF.

Download data:

    ./download_iwslt_2017_data.sh


Train the model:

       ./scripts/train.sh

*the training process can be interrupted at any time. The best checkpoint will always be saved automatically.

Evaluate the model:

       ./scripts/evaluate.sh

## For Windows (Command Prompt / PowerShell users)
Manually create and activate a virtual environment:

        python -m venv mt_env
        mt_env\Scripts\activate

Note: The make_virtualenv.sh script will not work in native Windows shells.

Manually download the dataset

Open the download_iwslt_2017_data.sh file in a text editor and run the commands one-by-one in your shell.
Alternatively, use Git Bash or WSL to run it directly.

Modify, train, and evaluate
Once setup is complete, use the instructions in the exercise PDF to run training and evaluation (either by adapting the .sh scripts manually, or by using Git Bash/WSL).

#### Notes for Windows Users

  Using Git Bash or WSL is highly recommended for compatibility.

  If using native PowerShell or Command Prompt:

  Manual recreation of shell script steps will be necessary.

  Always activate your virtual environment before running any training or evaluation steps.

